{
  "experiment_id": "C02",
  "created_at": "2025-11-17T03:36:17.034734+00:00",
  "dataset_path": "data/Big_AHR.csv",
  "cleaning": "baseline",
  "nlp_method": "keras_tokenizer",
  "embedding": "word2vec",
  "embedding_dim": 128,
  "max_len": 256,
  "vocab_size": 30001,
  "num_folds": 3,
  "folds": [
    1,
    2,
    3
  ],
  "tokenizer_path": "/home/david/github/DeepLearningP2/artifacts/data/C02/tokenizer.json",
  "vectorizer_path": null,
  "embedding_matrix": "/home/david/github/DeepLearningP2/artifacts/data/C02/embedding_matrix.npy",
  "clean_cache": "artifacts/cache/clean_baseline.joblib",
  "fold_indices_path": "artifacts/cache/folds_seed42_k3.json",
  "notes": "C02 baseline+tokenizer+word2vec",
  "seed": 42
}